"""
Mﾃｳdulo: ｧｪ test_agente.py
Projeto: 祷 AI Game Learning

Este mﾃｳdulo contﾃｩm uma suﾃｭte completa de testes unitﾃ｡rios para a classe AgenteQLearning.
Os testes verificam se o agente de aprendizado por reforﾃｧo estﾃ｡ funcionando corretamente,
incluindo inicializaﾃｧﾃ｣o, aprendizado Q-Learning e estratﾃｩgia de escolha de aﾃｧﾃｵes.

Os testes sﾃ｣o projetados para serem didﾃ｡ticos e educativos, explicando claramente
o que estﾃ｡ sendo testado e por quﾃｪ. Eles servem tanto como validaﾃｧﾃ｣o do cﾃｳdigo
quanto como material de aprendizado sobre Q-Learning.

Para executar os testes, use um dos seguintes comandos:
    - python fase-2/jogo_da_velha/test/test_agente.py
    - py -m test.test_agente (a partir do diretﾃｳrio fase-2/jogo_da_velha)
"""

from ..agente import AgenteQLearning


def testar_inicializacao():
    """
    Testa se o AgenteQLearning ﾃｩ inicializado corretamente com os atributos esperados.

    Este teste verifica:
    - Se o agente pode ser criado com parﾃ｢metros personalizados
    - Se os atributos sﾃ｣o definidos corretamente (jogador, sﾃｭmbolo, alpha, etc.)
    - Se a tabela Q comeﾃｧa vazia (sem conhecimento prﾃｩvio)

    O teste cria um agente como jogador 'O' (jogador=2) e verifica se todos
    os atributos estﾃ｣o configurados conforme esperado.

    Raises:
        AssertionError: Se algum atributo do agente nﾃ｣o estiver correto.

    Example:
        >>> testar_inicializacao()
        --- INICIANDO TESTE 1: INICIALIZAﾃﾃグ DO AGENTE ---
        笨 Agente criado com sucesso como jogador 'O'.
        --- TESTE 1 FINALIZADO ---
    """
    print("--- INICIANDO TESTE 1: INICIALIZAﾃﾃグ DO AGENTE ---")

    # Cria um agente como jogador 'O' (jogador=2)
    agente = AgenteQLearning(jogador=2)

    # Verifica se o identificador do jogador estﾃ｡ correto
    assert agente.jogador == 2, "O jogador deveria ser 2 (jogador 'O')"

    # Verifica se o sﾃｭmbolo estﾃ｡ correto
    assert agente.simbolo == 'O', "O sﾃｭmbolo deveria ser 'O' para jogador 2"

    # Verifica se a taxa de aprendizado padrﾃ｣o estﾃ｡ correta
    assert agente.alpha == 0.5, "A taxa de aprendizado (alpha) padrﾃ｣o deveria ser 0.5"

    # Verifica se a tabela Q comeﾃｧa vazia (sem conhecimento prﾃｩvio)
    assert len(agente.tabela_q) == 0, "A tabela Q deveria comeﾃｧar vazia"

    print("笨 Agente criado com sucesso como jogador 'O'.")
    print("--- TESTE 1 FINALIZADO ---\n")


def testar_aprendizado_q_learning():
    """
    Testa se o algoritmo Q-Learning estﾃ｡ aplicando a Equaﾃｧﾃ｣o de Bellman corretamente.

    Este teste verifica se o mﾃｩtodo aprender() estﾃ｡ calculando e atualizando os valores Q
    de acordo com a fﾃｳrmula do Q-Learning:

        Q(estado, aﾃｧﾃ｣o) = Q(estado, aﾃｧﾃ｣o) + alpha * (recompensa + gamma * max(Q(prﾃｳximo_estado)) - Q(estado, aﾃｧﾃ｣o))

    O teste simula um cenﾃ｡rio especﾃｭfico:
    - Estado inicial: tabuleiro vazio
    - Aﾃｧﾃ｣o escolhida: jogar no centro (posiﾃｧﾃ｣o 4)
    - Prﾃｳximo estado: tabuleiro com X no centro
    - Melhor valor Q futuro conhecido: 0.8
    - Recompensa imediata: 0.0 (jogo continua)

    Cﾃ｡lculo esperado:
        Q_novo = 0 + 0.5 * (0 + 0.9 * 0.8 - 0) = 0.36

    Este teste ﾃｩ fundamental para garantir que o agente estﾃ｡ aprendendo corretamente
    e ajustando seus valores Q baseado nas recompensas futuras esperadas.

    Raises:
        AssertionError: Se o valor Q calculado nﾃ｣o corresponder ao valor esperado.

    Note:
        Este teste valida a implementaﾃｧﾃ｣o do aprendizado Temporal Difference (TD),
        que ﾃｩ o coraﾃｧﾃ｣o do algoritmo Q-Learning.
    """
    print("--- INICIANDO TESTE 2: APRENDIZADO (ATUALIZAﾃﾃグ DE Q-VALOR) ---")

    # Cria um agente com parﾃ｢metros especﾃｭficos para o teste
    agente = AgenteQLearning(alpha=0.5, gamma=0.9)

    # Define o estado inicial: tabuleiro completamente vazio
    estado_inicial = (0, 0, 0, 0, 0, 0, 0, 0, 0)

    # Aﾃｧﾃ｣o escolhida: jogar no centro do tabuleiro (posiﾃｧﾃ｣o 4)
    posicao_escolhida = 4

    # Prﾃｳximo estado apﾃｳs a jogada: X no centro
    proximo_estado = (0, 0, 0, 0, 1, 0, 0, 0, 0)

    # Recompensa imediata: 0.0 (o jogo continua, nﾃ｣o hﾃ｡ vitﾃｳria/derrota ainda)
    recompensa_imediata = 0.0

    # Simula que jﾃ｡ conhecemos algumas aﾃｧﾃｵes no prﾃｳximo estado
    # A melhor aﾃｧﾃ｣o futura tem valor Q de 0.8
    agente.tabela_q[proximo_estado] = {0: 0.5, 1: 0.8, 2: 0.3}

    # Obtﾃｩm o valor Q atual (deve ser 0.0, pois ﾃｩ um estado novo)
    valor_q_antigo = agente.obter_valor_q(estado_inicial, posicao_escolhida)
    print(f"Opiniﾃ｣o antiga sobre jogar no centro: {valor_q_antigo}")

    # Aplica o aprendizado Q-Learning
    # finalizado=False porque o jogo ainda nﾃ｣o terminou
    agente.atualizar_valor_q(
        estado_inicial,
        posicao_escolhida,
        recompensa_imediata,
        proximo_estado,
        finalizado=False
    )

    # Obtﾃｩm o novo valor Q apﾃｳs o aprendizado
    valor_q_novo = agente.obter_valor_q(estado_inicial, posicao_escolhida)

    # Cﾃ｡lculo esperado usando a fﾃｳrmula do Q-Learning:
    # Q_novo = 0 + 0.5 * (0 + 0.9 * 0.8 - 0) = 0.36
    print(f"Nova opiniﾃ｣o sobre jogar no centro: {valor_q_novo:.2f}")

    # Verifica se o cﾃ｡lculo estﾃ｡ correto (com tolerﾃ｢ncia para arredondamento)
    assert round(valor_q_novo, 2) == 0.36, (
        f"O valor Q deveria ser 0.36, mas foi {valor_q_novo:.2f}. "
        "A fﾃｳrmula do Q-Learning pode estar incorreta."
    )

    print("笨 O Agente ajustou sua estratﾃｩgia corretamente!")
    print("--- TESTE 2 FINALIZADO ---\n")


def testar_estrategia_epsilon_greedy():
    """
    Testa se a estratﾃｩgia Epsilon-Greedy estﾃ｡ funcionando corretamente.

    A estratﾃｩgia Epsilon-Greedy ﾃｩ fundamental para o aprendizado por reforﾃｧo, pois
    equilibra dois comportamentos importantes:
    - Exploraﾃｧﾃ｣o: tentar aﾃｧﾃｵes novas/aleatﾃｳrias para descobrir estratﾃｩgias melhores
    - Exploraﾃｧﾃ｣o: usar o conhecimento jﾃ｡ adquirido para escolher as melhores aﾃｧﾃｵes

    Este teste verifica dois cenﾃ｡rios extremos:
    1. Agente Aventureiro (epsilon=1.0): sempre explora, escolhendo aﾃｧﾃｵes aleatﾃｳrias
    2. Agente Estrategista (epsilon=0.0): sempre explora, escolhendo a melhor aﾃｧﾃ｣o conhecida

    O teste garante que:
    - Com epsilon alto, o agente escolhe aﾃｧﾃｵes aleatﾃｳrias (exploraﾃｧﾃ｣o)
    - Com epsilon baixo, o agente escolhe a aﾃｧﾃ｣o com maior valor Q (exploraﾃｧﾃ｣o)
    - A aﾃｧﾃ｣o escolhida sempre estﾃ｡ na lista de aﾃｧﾃｵes vﾃ｡lidas

    Raises:
        AssertionError: Se a estratﾃｩgia Epsilon-Greedy nﾃ｣o estiver funcionando corretamente.

    Note:
        Em um cenﾃ｡rio real, epsilon geralmente comeﾃｧa alto (1.0) e decai gradualmente,
        permitindo que o agente explore no inﾃｭcio e depois explore mais conforme aprende.
    """
    print("--- INICIANDO TESTE 3: ESCOLHA DE Aﾃﾃグ (EPSILON-GREEDY) ---")

    # Define um estado de teste: algumas posiﾃｧﾃｵes jﾃ｡ ocupadas
    estado_teste = (1, 2, 0, 0, 0, 0, 0, 0, 0)

    # Lista de aﾃｧﾃｵes vﾃ｡lidas (posiﾃｧﾃｵes vazias no tabuleiro)
    acoes_validas = [2, 3, 4, 5, 6, 7, 8]

    # --- CENﾃヽIO 1: AGENTE AVENTUREIRO (100% Exploraﾃｧﾃ｣o) ---
    # Epsilon = 1.0 significa 100% de chance de escolher uma aﾃｧﾃ｣o aleatﾃｳria
    agente_aventureiro = AgenteQLearning(epsilon=1.0)
    acao_escolhida_aventureiro = agente_aventureiro.escolher_acao(
        estado_teste,
        acoes_validas,
        em_treinamento=True
    )
    print(
        f"Agente Aventureiro (ﾎｵ=1.0) escolheu a aﾃｧﾃ｣o: {acao_escolhida_aventureiro}")

    # Verifica se a aﾃｧﾃ｣o escolhida estﾃ｡ na lista de aﾃｧﾃｵes vﾃ｡lidas
    assert acao_escolhida_aventureiro in acoes_validas, (
        f"A aﾃｧﾃ｣o escolhida ({acao_escolhida_aventureiro}) deve estar na lista de aﾃｧﾃｵes vﾃ｡lidas."
    )

    # --- CENﾃヽIO 2: AGENTE ESTRATEGISTA (100% Exploraﾃｧﾃ｣o) ---
    # Epsilon = 0.0 significa 0% de chance de explorar, sempre escolhe a melhor aﾃｧﾃ｣o
    agente_estrategista = AgenteQLearning(epsilon=0.0)

    # Prﾃｩ-popula a tabela Q com valores conhecidos
    # A aﾃｧﾃ｣o 4 tem o maior valor Q (0.9), entﾃ｣o deve ser escolhida
    agente_estrategista.tabela_q[estado_teste] = {
        2: 0.5,  # Aﾃｧﾃ｣o 2: valor Q mﾃｩdio
        3: 0.1,  # Aﾃｧﾃ｣o 3: valor Q baixo
        4: 0.9   # Aﾃｧﾃ｣o 4: valor Q alto (melhor aﾃｧﾃ｣o)
    }

    acao_escolhida_estrategista = agente_estrategista.escolher_acao(
        estado_teste,
        acoes_validas,
        em_treinamento=True
    )
    print(
        f"Agente Estrategista (ﾎｵ=0.0) escolheu a aﾃｧﾃ｣o: {acao_escolhida_estrategista}")

    # Verifica se escolheu a melhor aﾃｧﾃ｣o conhecida (aﾃｧﾃ｣o 4 com valor Q 0.9)
    assert acao_escolhida_estrategista == 4, (
        f"Com epsilon=0.0, o agente deveria escolher a melhor aﾃｧﾃ｣o (4), "
        f"mas escolheu {acao_escolhida_estrategista}."
    )

    print("笨 O Agente estﾃ｡ balanceando exploraﾃｧﾃ｣o e estratﾃｩgia como esperado.")
    print("--- TESTE 3 FINALIZADO ---\n")


def executar_todos_testes():
    """
    Executa toda a suﾃｭte de testes do AgenteQLearning.

    Esta funﾃｧﾃ｣o orquestra a execuﾃｧﾃ｣o de todos os testes unitﾃ｡rios, fornecendo
    feedback claro sobre o progresso e resultados de cada teste. Ela serve
    como ponto de entrada principal para validar a funcionalidade do agente.

    A ordem dos testes ﾃｩ importante:
    1. Teste de inicializaﾃｧﾃ｣o (base para todos os outros)
    2. Teste de aprendizado (validaﾃｧﾃ｣o do algoritmo Q-Learning)
    3. Teste de escolha de aﾃｧﾃ｣o (validaﾃｧﾃ｣o da estratﾃｩgia Epsilon-Greedy)

    Se todos os testes passarem, uma mensagem de sucesso ﾃｩ exibida. Se algum
    teste falhar, uma exceﾃｧﾃ｣o AssertionError serﾃ｡ levantada com detalhes sobre
    o que falhou.

    Raises:
        AssertionError: Se algum dos testes falhar.

    Example:
        >>> executar_todos_testes()
        ==================================================
        ｧｪ INICIANDO BATERIA DE TESTES DO AGENTE ｧｪ
        ==================================================
        ...
        ==================================================
        笨 TODOS OS TESTES DO AGENTE CONCLUﾃ好OS COM SUCESSO!
        ==================================================
    """
    print("\n" + "="*50)
    print("ｧｪ INICIANDO BATERIA DE TESTES DO AGENTE ｧｪ")
    print("="*50 + "\n")

    # Executa os testes na ordem lﾃｳgica
    testar_inicializacao()
    testar_aprendizado_q_learning()
    testar_estrategia_epsilon_greedy()

    print("="*50)
    print("笨 TODOS OS TESTES DO AGENTE CONCLUﾃ好OS COM SUCESSO!")
    print("="*50 + "\n")


if __name__ == "__main__":
    """
    Ponto de entrada do mﾃｳdulo quando executado diretamente.

    Quando o arquivo ﾃｩ executado como script (nﾃ｣o importado como mﾃｳdulo),
    executa automaticamente toda a suﾃｭte de testes.
    """
    executar_todos_testes()
