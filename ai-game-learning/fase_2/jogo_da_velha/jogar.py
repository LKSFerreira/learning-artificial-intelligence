"""
M√≥dulo: üïπÔ∏è jogar.py
Projeto: üìò AI Game Learning

Este m√≥dulo implementa a interface de jogo interativa, permitindo que um
jogador humano desafie a IA treinada em uma partida de Jogo da Velha.

O m√≥dulo gerencia todo o fluxo de intera√ß√£o humano-IA:
- Carregamento do modelo treinado (Superagente)
- Interface de usu√°rio para escolha de s√≠mbolo e jogadas
- Sistema de regras especiais para determinar quem come√ßa cada partida
- Exibi√ß√£o visual do tabuleiro e feedback sobre o progresso
- Gerenciamento de m√∫ltiplas partidas consecutivas

Sistema de Regras Especiais:
O jogo implementa um sistema din√¢mico de escolha do jogador inicial baseado
no resultado da partida anterior:
- Se o humano venceu: Pode escolher quem come√ßa (recompensa)
- Se o humano perdeu: A IA sempre come√ßa (dificuldade adicional)
- Se houve empate: Sorteio aleat√≥rio (justi√ßa)

Este sistema torna o jogo mais interessante e desafiador, criando uma
experi√™ncia de jogo mais envolvente e din√¢mica.
"""

import os
import sys
from pathlib import Path
import random
import time
from typing import Optional, Tuple

from .ambiente import AmbienteJogoDaVelha
from .agente import AgenteQLearning


def limpar_tela():
    """
    Limpa o console para melhorar a experi√™ncia visual do usu√°rio.

    Detecta automaticamente o sistema operacional e usa o comando apropriado:
    - Windows: 'cls'
    - Unix/Linux/Mac: 'clear'

    Note:
        Este m√©todo n√£o retorna nada, apenas executa o comando de limpeza.
        √ötil para manter a interface limpa entre turnos e partidas.
    """
    os.system('cls' if os.name == 'nt' else 'clear')


def obter_jogada_humano(ambiente: AmbienteJogoDaVelha) -> int:
    """
    Solicita e valida a jogada do jogador humano.

    Esta fun√ß√£o exibe o tabuleiro atual com as posi√ß√µes dispon√≠veis numeradas,
    permitindo que o jogador veja claramente onde pode jogar. Ela valida a
    entrada do usu√°rio, garantindo que:
    - A entrada seja um n√∫mero v√°lido
    - A posi√ß√£o escolhida esteja realmente vazia
    - A posi√ß√£o exista no tabuleiro

    Args:
        ambiente: Inst√¢ncia do ambiente do jogo contendo o estado atual.

    Returns:
        √çndice da posi√ß√£o escolhida pelo jogador (0 a N¬≤-1).

    Note:
        Esta fun√ß√£o entra em um loop at√© que o jogador forne√ßa uma entrada v√°lida.
        Ela fornece feedback claro sobre erros (posi√ß√£o ocupada, entrada inv√°lida, etc.).
    """
    acoes_validas = ambiente.obter_acoes_validas()
    
    # Exibe o tabuleiro com n√∫meros nas posi√ß√µes vazias para facilitar a escolha
    print("\n--- Tabuleiro com Posi√ß√µes Livres ---")
    simbolos = {0: ' ', 1: 'X', 2: 'O'}
    
    # Itera sobre cada linha do tabuleiro
    for indice_linha in range(ambiente.dimensao):
        inicio_linha = indice_linha * ambiente.dimensao
        fim_linha = inicio_linha + ambiente.dimensao
        
        # Cria a linha: mostra n√∫meros nas posi√ß√µes vazias, s√≠mbolos nas ocupadas
        linha = [
            str(indice) if ambiente.tabuleiro[indice] == 0 
            else simbolos[ambiente.tabuleiro[indice]]
            for indice in range(inicio_linha, fim_linha)
        ]
        print(" " + " | ".join(linha))
        
        # Adiciona separador horizontal entre linhas
        if indice_linha < ambiente.dimensao - 1:
            print("---" + "+---" * (ambiente.dimensao - 1))
    
    print("------------------------------------")

    # Loop de valida√ß√£o: continua at√© receber uma entrada v√°lida
    while True:
        try:
            posicao_str = input(f"Sua vez. Escolha uma posi√ß√£o livre ({acoes_validas}): ")
            posicao = int(posicao_str)
            
            # Verifica se a posi√ß√£o escolhida est√° na lista de a√ß√µes v√°lidas
            if posicao in acoes_validas:
                return posicao
            else:
                print("‚ùå Jogada inv√°lida! A posi√ß√£o n√£o est√° livre ou n√£o existe.")
        except ValueError:
            print("‚ùå Entrada inv√°lida. Por favor, digite um n√∫mero.")


def determinar_jogador_inicial(resultado_anterior: int, jogador_humano: int) -> int:
    """
    Determina qual jogador come√ßa a partida baseado no resultado anterior.

    Este m√©todo implementa um sistema de regras din√¢mico que torna o jogo
    mais interessante e desafiador:

    - Primeira partida ou empate anterior: Sorteio aleat√≥rio (justi√ßa)
    - Humano perdeu: IA come√ßa (aumenta dificuldade como "puni√ß√£o")
    - Humano venceu: Humano escolhe quem come√ßa (recompensa)

    Este sistema cria uma experi√™ncia de jogo mais envolvente, onde o
    desempenho do jogador afeta as condi√ß√µes da pr√≥xima partida.

    Args:
        resultado_anterior: Resultado da partida anterior.
            -1: Primeira partida (ainda n√£o houve resultado)
            0: Empate
            1 ou 2: Vencedor (1='X', 2='O')
        jogador_humano: Identificador do jogador humano (1 para 'X', 2 para 'O').

    Returns:
        Identificador do jogador que come√ßar√° a partida (1 para 'X', 2 para 'O').

    Note:
        Se o humano venceu, esta fun√ß√£o solicita input do usu√°rio para escolher
        quem come√ßa. Em outros casos, a decis√£o √© autom√°tica.
    """
    # Calcula qual √© o jogador da IA (oposto ao humano)
    jogador_ia = 2 if jogador_humano == 1 else 1
    
    # Caso 1: Primeira partida ou empate anterior
    # Sorteio aleat√≥rio para ser justo
    if resultado_anterior == -1 or resultado_anterior == 0:
        print("\nüé≤ Resultado anterior foi empate ou √© a primeira partida. Sorteando quem come√ßa...")
        time.sleep(1)  # Pausa para dar tempo de ler a mensagem
        return random.choice([1, 2])
    
    # Caso 2: Humano perdeu a √∫ltima partida
    # IA come√ßa como "puni√ß√£o" (aumenta a dificuldade)
    elif resultado_anterior == jogador_ia:
        print("\nü§ñ Voc√™ perdeu a √∫ltima partida. A IA come√ßa como puni√ß√£o!")
        time.sleep(1)
        return jogador_ia
    
    # Caso 3: Humano venceu a √∫ltima partida
    # Humano escolhe quem come√ßa como recompensa
    else:
        print("\nüèÜ Voc√™ venceu a √∫ltima partida! Como recompensa, voc√™ escolhe quem come√ßa.")
        while True:
            escolha = input("Voc√™ quer come√ßar (S) ou deixar a IA come√ßar (N)? [S/N]: ").upper()
            if escolha == 'S':
                return jogador_humano
            elif escolha == 'N':
                return jogador_ia
            else:
                print("Op√ß√£o inv√°lida. Digite 'S' para sim ou 'N' para n√£o.")


def exibir_regras_iniciais():
    """
    Exibe as regras especiais do jogo na primeira partida.

    Informa o jogador sobre o sistema din√¢mico de escolha do jogador inicial,
    explicando como o resultado de cada partida afeta a pr√≥xima. Isso ajuda
    o jogador a entender as regras e estrat√©gias do jogo.

    Note:
        Esta fun√ß√£o pausa a execu√ß√£o aguardando o jogador pressionar Enter,
        garantindo que ele tenha tempo para ler as regras.
    """
    print("\n" + "-"*50)
    print("üìú REGRAS ESPECIAIS DE QUEM COME√áA üìú")
    print("-"*50)
    print("A cada nova partida, a ordem de in√≠cio √© decidida assim:")
    print(" ‚Ä¢ Se voc√™ VENCEU: Voc√™ tem o direito de escolher quem come√ßa.")
    print(" ‚Ä¢ Se voc√™ PERDEU: A IA sempre come√ßar√° a pr√≥xima partida.")
    print(" ‚Ä¢ Se houve EMPATE: Um novo sorteio decidir√° quem come√ßa.")
    print("-"*50)
    input("\nPressione Enter para continuar...")


def iniciar_partida_humano_vs_ia(agente_ia: AgenteQLearning, resultado_anterior: int = -1, jogador_humano_definido: Optional[int] = None) -> Tuple[int, int]:
    """
    Gerencia o fluxo completo de uma partida entre humano e IA.

    Esta fun√ß√£o coordena toda a partida do in√≠cio ao fim:
    1. Configura o ambiente e os jogadores
    2. Determina quem come√ßa (baseado no resultado anterior)
    3. Alterna entre jogador humano e IA at√© a partida terminar
    4. Exibe o resultado final
    5. Retorna informa√ß√µes para a pr√≥xima partida

    O jogo √© executado em modo de performance m√°xima (sem explora√ß√£o),
    garantindo que a IA sempre escolha a melhor a√ß√£o conhecida.

    Args:
        agente_ia: Inst√¢ncia do agente Q-Learning treinado (Superagente).
        resultado_anterior: Resultado da partida anterior.
            -1: Primeira partida
            0: Empate anterior
            1 ou 2: Vencedor anterior
        jogador_humano_definido: Identificador do jogador humano (1='X', 2='O').
            Se None, solicita ao jogador na primeira partida.

    Returns:
        Tupla contendo:
        - vencedor (int): Identificador do vencedor (1, 2, ou 0 para empate)
        - jogador_humano (int): Identificador do jogador humano (1 ou 2)

    Note:
        - A IA joga com em_treinamento=False (sempre escolhe a melhor a√ß√£o)
        - O ambiente √© reiniciado automaticamente para uma nova partida
        - A fun√ß√£o exibe o tabuleiro ap√≥s cada jogada
    """
    limpar_tela()
    print("\n" + "="*50)
    print("‚öîÔ∏è NOVA PARTIDA ‚öîÔ∏è")
    print("="*50)

    # Cria um novo ambiente para esta partida
    ambiente = AmbienteJogoDaVelha(dimensao=3)
    
    # --- CONFIGURA√á√ÉO INICIAL DOS JOGADORES ---
    jogador_humano = jogador_humano_definido
    
    # Se √© a primeira partida, solicita ao jogador escolher seu s√≠mbolo
    if resultado_anterior == -1:
        while jogador_humano is None:
            escolha = input("Voc√™ quer ser 'X' ou 'O'? [X/O]: ").upper()
            if escolha == 'X':
                jogador_humano = 1
            elif escolha == 'O':
                jogador_humano = 2
            else:
                print("Op√ß√£o inv√°lida. Digite 'X' ou 'O'.")
        
        # Configura o agente IA para jogar com o s√≠mbolo oposto
        agente_ia.jogador = 2 if jogador_humano == 1 else 1
        agente_ia.simbolo = 'O' if agente_ia.jogador == 2 else 'X'
    
    # Exibe a configura√ß√£o dos jogadores
    simbolo_humano = 'X' if jogador_humano == 1 else 'O'
    print(f"\nVoc√™ joga como '{simbolo_humano}'. A IA jogar√° como '{agente_ia.simbolo}'.")
    
    # Determina quem come√ßa baseado no resultado anterior
    ambiente.jogador_atual = determinar_jogador_inicial(resultado_anterior, jogador_humano)
    simbolo_inicial = 'X' if ambiente.jogador_atual == 1 else 'O'
    print(f"O jogador '{simbolo_inicial}' come√ßa a partida!")
    
    # Exibe regras na primeira partida, ou aguarda confirma√ß√£o nas demais
    if resultado_anterior == -1:
        exibir_regras_iniciais()
    else:
        input("\nPressione Enter para come√ßar a partida...")

    # --- LOOP PRINCIPAL DA PARTIDA ---
    while not ambiente.partida_finalizada:
        limpar_tela()
        simbolo_humano = 'X' if jogador_humano == 1 else 'O'
        print(f"Voc√™ ('{simbolo_humano}') vs. IA ('{agente_ia.simbolo}')\n")
        ambiente.exibir_tabuleiro()
        
        # Obt√©m o estado atual e as a√ß√µes v√°lidas
        estado_atual = ambiente.obter_estado_como_tupla()
        acoes_validas = ambiente.obter_acoes_validas()

        # Decide se √© a vez do humano ou da IA
        if ambiente.jogador_atual == jogador_humano:
            # Turno do jogador humano
            acao = obter_jogada_humano(ambiente)
        else:
            # Turno da IA
            print(f"\nTurno da IA ({agente_ia.simbolo})... pensando...")
            time.sleep(1)  # Pausa para criar suspense
            
            # IA escolhe a melhor a√ß√£o conhecida (sem explora√ß√£o)
            acao = agente_ia.escolher_acao(estado_atual, acoes_validas, em_treinamento=False)
            print(f"IA escolheu a posi√ß√£o {acao}.")
            time.sleep(1)  # Pausa para o jogador ver a escolha

        # Executa a jogada escolhida no ambiente
        ambiente.executar_jogada(acao)

    # --- EXIBI√á√ÉO DO RESULTADO FINAL ---
    limpar_tela()
    print("\n" + "="*50)
    print("FIM DE JOGO!")
    print("="*50)
    ambiente.exibir_tabuleiro()
    
    # Determina e exibe o resultado
    if ambiente.vencedor == 0:
        print("Resultado: ü§ù EMPATE! Voc√™ conseguiu igualar o mestre!")
    elif ambiente.vencedor == jogador_humano:
        print("Resultado: üèÜ IMPOSS√çVEL! Voc√™ venceu! Encontrou um bug ou uma falha no treinamento?")
    else:
        print("Resultado: ü§ñ DERROTA! A IA venceu, como esperado.")
    
    print("="*50 + "\n")
    return ambiente.vencedor, jogador_humano


def main():
    """
    Fun√ß√£o principal que gerencia o jogo completo e m√∫ltiplas partidas.

    Esta fun√ß√£o:
    1. Carrega o modelo treinado (Superagente)
    2. Gerencia o loop principal de m√∫ltiplas partidas
    3. Mant√©m o estado entre partidas (resultado anterior, jogador escolhido)
    4. Permite ao jogador continuar jogando ou sair

    O jogo continua at√© que o jogador decida parar, mantendo o hist√≥rico
    de resultados para aplicar as regras especiais de quem come√ßa.

    Note:
        - O modelo esperado √© o Superagente final (resultado da mesclagem)
        - Se o modelo n√£o for encontrado, o programa encerra com erro
        - O jogador escolhe seu s√≠mbolo apenas na primeira partida
    """
    limpar_tela()
    print("\n" + "="*50)
    print("ü§ñ BEM-VINDO AO DESAFIO CONTRA A IA MESTRE! ü§ñ")
    print("="*50)

    # Define o caminho do modelo treinado (Superagente)
    caminho_modelo = Path("modelos_treinados") / "superagente_final_3x3.pkl"
    
    # Verifica se o modelo existe antes de tentar carregar
    if not caminho_modelo.exists():
        print(f"\n‚ùå ERRO: Modelo '{caminho_modelo}' n√£o encontrado.")
        print("   Execute o treinamento e a mesclagem dos modelos primeiro.")
        sys.exit(1)
        
    # Carrega o Superagente treinado
    # epsilon=0 garante que a IA sempre escolha a melhor a√ß√£o (sem explora√ß√£o)
    agente_ia = AgenteQLearning.carregar(str(caminho_modelo), jogador=0, epsilon=0)

    # Vari√°veis de controle do loop de partidas
    jogar_novamente = True
    resultado_anterior = -1  # -1 indica primeira partida
    jogador_humano: Optional[int] = None  # Ser√° definido na primeira partida

    # Loop principal: continua at√© o jogador decidir parar
    while jogar_novamente:
        # Executa uma partida completa
        resultado_atual, jogador_humano_atual = iniciar_partida_humano_vs_ia(
            agente_ia,
            resultado_anterior,
            jogador_humano
        )
        
        # Atualiza o resultado anterior para a pr√≥xima partida
        resultado_anterior = resultado_atual
        
        # Salva o jogador escolhido na primeira partida
        if jogador_humano is None:
            jogador_humano = jogador_humano_atual
        
        # Pergunta se o jogador quer continuar
        resposta = input("üéÆ Jogar novamente? (s/n): ").strip().lower()
        if resposta not in ['s', 'sim']:
            jogar_novamente = False
    
    print("\nüëã Obrigado por jogar! At√© a pr√≥xima.")


if __name__ == "__main__":
    """
    Ponto de entrada do m√≥dulo quando executado diretamente.

    Quando o arquivo √© executado como script, inicia automaticamente
    o jogo contra a IA.
    """
    main()
